# -*- coding: utf-8 -*-
"""Helper_Functions.py

Automatically generated by Colaboratory.

"""

#PyTorchs
import torch
from torch import nn
import torchvision
from torchvision import datasets, transforms
from torchvision.transforms import ToTensor
from torch.utils.data import DataLoader

# numpy
import numpy as np
# random
import random
# math
import math
# plot
import matplotlib.pyplot as plt
# timer
from timeit import default_timer as timer
# os
import os
# tqdm
from tqdm.auto import tqdm
# zipfile
import zipfile
# pathlib
from pathlib import Path
# requests
import requests
# typing
from typing import Tuple, Dict, List

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device

def accuracy_fn(y_true: torch.Tensor, y_pred: torch.Tensor):
  """Calculates accuracy of model
  Args: 'y_true' is the true test tensor,
  'y_pred' is the prediction tensor"""

  correct = torch.eq(y_true,y_pred).sum().item()
  acc = (correct/len(y_pred)) * 100
  return acc

def train_time_fn(start: float, end: float, device: torch.device = None):
  """ Prints difference between start and end time."""
  total_time = end - start
  print(f"Train time on {device}: {total_time:.3f} seconds")
  return total_time

def train_step(model: torch.nn.Module,
               data_loader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               optimizer: torch.optim.Optimizer,
               accuracy_fn,
               device: torch.device = device):
  """Performs a training with model trying to learn on data_loader"""
  train_loss, train_acc = 0, 0

  # model training mode
  model.train()

  # Add a loop to loop through the training batches
  for batch, (X,y) in enumerate(data_loader):
    # putting datas on device
    X, y = X.to(device), y.to(device)

    # forward (logits format)
    y_pred = model(X)

    # calculate the loss (per batch)
    loss = loss_fn(y_pred,y)
    train_loss += loss # accumulate train loss
    train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)) # logits -> prediction labels

    # optimizer.zero_grad()
    optimizer.zero_grad()

    # loss backward (back propagation)
    loss.backward()

    # gradient descenting (optimizer step)
    optimizer.step()

  # Divide total train loss and acc by lenght of train dataloader
  train_loss /= len(data_loader)
  train_acc /= len(data_loader)
  print(f"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%.")

def test_step(model: torch.nn.Module,
               data_loader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               accuracy_fn,
               device: torch.device = device):
  """Performs a testing with model trying to evaluate on data_loader"""
  test_loss, test_acc = 0, 0
  # putting model in valuation mode
  model.eval()
  with torch.inference_mode():
    for X, y in data_loader:
      # putting datas on device
      X, y = X.to(device), y.to(device)

      # forward
      test_pred = model(X) # output is in logit format

      # calculate loss (accumulatively)
      test_loss += loss_fn(test_pred,y)

      # calculate accuracy
      test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1)) # logits -> labels

    # calculate the test loss average per batch
    test_loss /= len(data_loader)

    # calculate the test acc average per batch
    test_acc /= len(data_loader)
    print(f"Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%.")

def eval_model(model: torch.nn.Module,
               data_loader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               accuracy_fn,
               device: torch.device):
  """ Returns a dictionory containing the results of model predicting on data loader. (only works when model was created with a class)"""
  loss, acc = 0, 0
  model.eval()
  with torch.inference_mode():
    for X, y in tqdm(data_loader):
      # device agnostic code
      X, y = X.to(device), y.to(device)

      # make predictions
      y_pred = model(X)

      # accumulate the loss and acc values per batch
      loss += loss_fn(y_pred,y)
      acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))
    # scale loss and acc to find the average loss/acc per batch
    loss /= len(data_loader)
    acc /= len(data_loader)
  return {"model_name": model.__class__.__name__,# only works when model was created with a class
          "model_loss": loss.item(),
          "model_acc": acc}

def make_predictions(model: torch.nn.Module,
                     data: list,
                     device: torch.device = device):
  """Provides to get prediction probability from model
  (prediction logits -> prediction probability -> prediction label) and returns torch.Tensor.

  Args: 'model' must be torch.nn.Module format,
  'data' must be List format,
  'device' must be torch.device format
  """

  pred_probs = []
  model.to(device)
  model.eval()
  with torch.inference_mode():
    for sample in data:
      # Prepare sample ()
      sample = torch.unsqueeze(sample, dim =0).to(device)

      # forward pass
      pred_logit = model(sample)

      # getting prediction probability (logit -> prediction probability)
      pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)

      # getting pred_prob aff the gpu for further calculations
      pred_probs.append(pred_prob.cpu())

  # stack the pred_probs to turn list into a tensor
  return torch.stack(pred_probs).argmax(dim=1)

# plot predictions
def plot_predictions(test_data_samples: list,
                     test_data_labels: list,
                     classes: list,
                     pred_classes: torch.Tensor,
                     n_samples: int):
  """
  Provides to plotting prediction and true results.
  Args: 'test_data_samples' -> list (test_data_samples),
  'test_data_labels' -> list (test_data_labels),
  'classes' -> must be x.classes: x => tochvision.datasets
  'pred_classes' -> (toch.tensor) the prediction labels
  'n_samples' -> sample number

   """
  try:
    plt.figure(figsize=(n_samples,n_samples))
    nrows = int(math.sqrt(n_samples))
    ncols = int(math.ceil(n_samples / nrows))

    for index, sample in enumerate(test_data_samples):
      # subplot
      plt.subplot(nrows, ncols, index+1)

      # plot target img
      plt.imshow(sample.reshape(sample.shape[1],sample.shape[2]), cmap="gray")

      # Find the prediction
      pred_label = classes[pred_classes[index]]

      # truth label
      truth_label = classes[test_data_labels[index]]

      # creating a title for the plot
      title_text = f"pred: {pred_label} | truth: {truth_label}"

      # checking equality between truth and pred labels
      if pred_label == truth_label:
        plt.title(title_text, fontsize=10, c="g") # green colour will be showed if prediction is correct
      else:
        plt.title(title_text, fontsize=10, c="r") # red colour will be showed if prediction is not correct
      plt.axis("off")
  except:
    raise TypeError(f"incorrect value type")

def walk_through_dir(dir_path):
    """
    Walks through dir_path returning its contents.
    Args:
    dir_path (str): target directory

    Returns:
    A print out of:
      number of subdiretories in dir_path
      number of images (files) in each subdirectory
      name of each subdirectory
    """
    for dirpath, dirnames, filenames in os.walk(dir_path):
        print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")

def class_from_dir(directory: str) -> Tuple[list[str], Dict[str, int]]:
  """ Finds the class folder names in a target directory."""
  try:
    # getting class names by scanning the target directory
    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())

    # getting class dictionary feature
    class_to_idx =  {class_name: i for i, class_name in enumerate(classes)}

    # return
    return classes, class_to_idx
  except:
    raise FileNotFoundError(f"Couldn't find any classes in {directory}...")
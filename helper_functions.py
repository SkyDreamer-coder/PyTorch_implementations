# -*- coding: utf-8 -*-
"""Helper_Functions.py

Automatically generated by Colaboratory.

"""

#PyTorchs
import torch
from torch import nn
import torchvision
from torchvision import datasets, transforms
from torchvision.transforms import ToTensor
from torch.utils.data import DataLoader

# numpy
import numpy as np
# random
import random
# math
import math
# plot
import matplotlib.pyplot as plt
# timer
from timeit import default_timer as timer
# os
import os
# tqdm
from tqdm.auto import tqdm
# zipfile
import zipfile
# pathlib
from pathlib import Path
# requests
import requests

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device

def accuracy_fn(y_true: torch.Tensor, y_pred: torch.Tensor):
  """Calculates accuracy of model
  Args: 'y_true' is the true test tensor,
  'y_pred' is the prediction tensor"""

  correct = torch.eq(y_true,y_pred).sum().item()
  acc = (correct/len(y_pred)) * 100
  return acc

def train_time_fn(start: float, end: float, device: torch.device = None):
  """ Prints difference between start and end time."""
  total_time = end - start
  print(f"Train time on {device}: {total_time:.3f} seconds")
  return total_time

def train_step(model: torch.nn.Module,
               data_loader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               optimizer: torch.optim.Optimizer,
               accuracy_fn,
               device: torch.device = device):
  """Performs a training with model trying to learn on data_loader"""
  train_loss, train_acc = 0, 0

  # model training mode
  model.train()

  # Add a loop to loop through the training batches
  for batch, (X,y) in enumerate(data_loader):
    # putting datas on device
    X, y = X.to(device), y.to(device)

    # forward (logits format)
    y_pred = model(X)

    # calculate the loss (per batch)
    loss = loss_fn(y_pred,y)
    train_loss += loss # accumulate train loss
    train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1)) # logits -> prediction labels

    # optimizer.zero_grad()
    optimizer.zero_grad()

    # loss backward (back propagation)
    loss.backward()

    # gradient descenting (optimizer step)
    optimizer.step()

  # Divide total train loss and acc by lenght of train dataloader
  train_loss /= len(data_loader)
  train_acc /= len(data_loader)
  print(f"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%.")

def test_step(model: torch.nn.Module,
               data_loader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               accuracy_fn,
               device: torch.device = device):
  """Performs a testing with model trying to evaluate on data_loader"""
  test_loss, test_acc = 0, 0
  # putting model in valuation mode
  model.eval()
  with torch.inference_mode():
    for X, y in data_loader:
      # putting datas on device
      X, y = X.to(device), y.to(device)

      # forward
      test_pred = model(X) # output is in logit format

      # calculate loss (accumulatively)
      test_loss += loss_fn(test_pred,y)

      # calculate accuracy
      test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1)) # logits -> labels

    # calculate the test loss average per batch
    test_loss /= len(data_loader)

    # calculate the test acc average per batch
    test_acc /= len(data_loader)
    print(f"Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%.")

def eval_model(model: torch.nn.Module,
               data_loader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               accuracy_fn,
               device: torch.device):
  """ Returns a dictionory containing the results of model predicting on data loader. (only works when model was created with a class)"""
  loss, acc = 0, 0
  model.eval()
  with torch.inference_mode():
    for X, y in tqdm(data_loader):
      # device agnostic code
      X, y = X.to(device), y.to(device)

      # make predictions
      y_pred = model(X)

      # accumulate the loss and acc values per batch
      loss += loss_fn(y_pred,y)
      acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))
    # scale loss and acc to find the average loss/acc per batch
    loss /= len(data_loader)
    acc /= len(data_loader)
  return {"model_name": model.__class__.__name__,# only works when model was created with a class
          "model_loss": loss.item(),
          "model_acc": acc}

def make_predictions(model: torch.nn.Module,
                     data: list,
                     device: torch.device = device):
  """Provides to get prediction probability from model
  (prediction logits -> prediction probability -> prediction label) and returns torch.Tensor.

  Args: 'model' must be torch.nn.Module format,
  'data' must be List format,
  'device' must be torch.device format
  """

  pred_probs = []
  model.to(device)
  model.eval()
  with torch.inference_mode():
    for sample in data:
      # Prepare sample ()
      sample = torch.unsqueeze(sample, dim =0).to(device)

      # forward pass
      pred_logit = model(sample)

      # getting prediction probability (logit -> prediction probability)
      pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)

      # getting pred_prob aff the gpu for further calculations
      pred_probs.append(pred_prob.cpu())

  # stack the pred_probs to turn list into a tensor
  return torch.stack(pred_probs).argmax(dim=1)

# plot predictions
def plot_predictions(data: torchvision.datasets,
                     pred_classes: torch.Tensor,
                     n_samples: int):
  test_samples = []
  test_labels = []

  for sample, label in random.sample(list(data), k=n_samples):
    test_samples.append(sample)
    test_labels.append(label)

  plt.figure(figsize=(9,9))
  nrows = int(math.sqrt(n_samples))
  ncols = int(math.ceil(n_samples / nrows))

  for index, sample in enumerate(test_samples):
    # subplot
    plt.subplot(nrows, ncols, index+1)

    # plot target img
    plt.imshow(sample.squeeze(), cmap="gray")

    # Find the prediction
    pred_label = data.classes[pred_classes[index]]

    # truth label
    truth_label = data.classes[test_labels[index]]

    # creating a title for the plot
    title_text = f"pred: {pred_label} | truth: {truth_label}"

    # checking equality between truth and pred labels
    if pred_label == truth_label:
      plt.title(title_text, fontsize=10, c="g") # green colour will be showed if prediction is correct
    else:
      plt.title(title_text, fontsize=10, c="r") # red colour will be showed if prediction is not correct
    plt.axis("off")

def walk_through_dir(dir_path):
    """
    Walks through dir_path returning its contents.
    Args:
    dir_path (str): target directory

    Returns:
    A print out of:
      number of subdiretories in dir_path
      number of images (files) in each subdirectory
      name of each subdirectory
    """
    for dirpath, dirnames, filenames in os.walk(dir_path):
        print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")